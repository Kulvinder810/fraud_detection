ğŸ“Œ Real-Time Data Pipeline using Kafka, Spark, and Databricks
ğŸš€ A scalable real-time data pipeline using Apache Kafka as a message broker, a Python Producer to simulate transactions, and a Databricks Consumer to process the data.

ğŸ“‚ Project Structure
bash
Copy
Edit
/project-root/
â”‚â”€â”€ producer/           # Python Kafka Producer
â”‚   â”œâ”€â”€ producer.py     # Sends messages to Kafka
â”‚â”€â”€ consumer/           # Databricks Consumer
â”‚   â”œâ”€â”€ consumer.py     # Reads and processes messages
â”‚â”€â”€ config/             # Stores configuration settings
â”‚   â”œâ”€â”€ config.py       # User-defined settings
â”‚â”€â”€ requirements.txt    # Python dependencies
â”‚â”€â”€ README.md           # Project documentation
â”‚â”€â”€ .gitignore          # Ignore unnecessary files
ğŸ› ï¸ Prerequisites
Ensure you have the following installed before proceeding:
âœ… Python 3.8+
âœ… Kafka & Zookeeper (Running on localhost or a cloud service)
âœ… Databricks Cluster (For consumer processing)
âœ… Confluent Kafka (Optional for managed Kafka)

âš™ï¸ Configuration Setup
Edit the config.py file inside the config/ folder to match your setup.

python
Copy
Edit
# Kafka Settings
KAFKA_BROKER = "localhost:9092"
KAFKA_TOPIC = "transactions"

ğŸš€ Running the Producer (Python)
1ï¸âƒ£ Navigate to the producer folder

bash
Copy
Edit
cd producer
2ï¸âƒ£ Install dependencies

bash
Copy
Edit
pip install -r ../requirements.txt
3ï¸âƒ£ Run the producer

bash
Copy
Edit
python producer.py
ğŸ“Œ This script will send transaction data to Kafka every few seconds.

ğŸ”¥ Running the Consumer (Databricks)
1ï¸âƒ£ Upload consumer.py to your Databricks workspace
2ï¸âƒ£ Attach it to a Databricks cluster
3ï¸âƒ£ Run the script in a notebook or as a job

ğŸ“Œ The consumer will read Kafka messages and process them in Databricks.

ğŸ“ˆ Monitoring Kafka Topics
To check if data is flowing correctly, run the following command:

bash
Copy
Edit
kafka-console-consumer --bootstrap-server localhost:9092 --topic transactions --from-beginning
ğŸ› Troubleshooting
âŒ Producer not sending messages?
âœ”ï¸ Ensure Kafka is running:

bash
Copy
Edit
zookeeper-server-start.sh config/zookeeper.properties  
kafka-server-start.sh config/server.properties  
âœ”ï¸ Verify your Kafka topic exists:

bash
Copy
Edit
kafka-topics --list --bootstrap-server localhost:9092
âŒ Databricks not receiving messages?
âœ”ï¸ Check if the consumer script is properly consuming from Kafka by running it manually in Databricks.


ğŸ’¡ Contributing
ğŸš€ Contributions are welcome! Feel free to submit a pull request or open an issue if you find any bugs or have feature requests.

ğŸ‘¨â€ğŸ’» Author
ğŸ‘¤ Kulvinder Singh
ğŸ”— github.com/Kulvinder810/
âœ‰ï¸ Contact: kuls810@gmail.com

ğŸ‰ Happy Coding! ğŸš€ğŸ”¥
Let me know if you need any modifications or improvements! ğŸš€







